/*
 * IDENTIFICATION:
 * stub generated by bootstrap_cmds-138
 * OPTIONS: 
 *	KernelServer
 */

/* Module mach_vm */

#define	__MIG_check__Request__mach_vm_subsystem__ 1

#include "mach_vm_server.h"

#ifndef	mig_internal
#define	mig_internal	static __inline__
#endif	/* mig_internal */

#ifndef	mig_external
#define mig_external
#endif	/* mig_external */

#if	!defined(__MigTypeCheck) && defined(TypeCheck)
#define	__MigTypeCheck		TypeCheck	/* Legacy setting */
#endif	/* !defined(__MigTypeCheck) */

#if	!defined(__MigKernelSpecificCode) && defined(_MIG_KERNEL_SPECIFIC_CODE_)
#define	__MigKernelSpecificCode	_MIG_KERNEL_SPECIFIC_CODE_	/* Legacy setting */
#endif	/* !defined(__MigKernelSpecificCode) */

#ifndef	LimitCheck
#define	LimitCheck 0
#endif	/* LimitCheck */

#ifndef	min
#define	min(a,b)  ( ((a) < (b))? (a): (b) )
#endif	/* min */

#if !defined(_WALIGN_)
#define _WALIGN_(x) (((x) + 3) & ~3)
#endif /* !defined(_WALIGN_) */

#if !defined(_WALIGNSZ_)
#define _WALIGNSZ_(x) _WALIGN_(sizeof(x))
#endif /* !defined(_WALIGNSZ_) */

#ifndef	UseStaticTemplates
#define	UseStaticTemplates	0
#endif	/* UseStaticTemplates */

#ifndef MIG_SERVER_ROUTINE
#define MIG_SERVER_ROUTINE
#endif

#ifndef	__DeclareRcvRpc
#define	__DeclareRcvRpc(_NUM_, _NAME_)
#endif	/* __DeclareRcvRpc */

#ifndef	__BeforeRcvRpc
#define	__BeforeRcvRpc(_NUM_, _NAME_)
#endif	/* __BeforeRcvRpc */

#ifndef	__AfterRcvRpc
#define	__AfterRcvRpc(_NUM_, _NAME_)
#endif	/* __AfterRcvRpc */

#ifndef	__DeclareRcvSimple
#define	__DeclareRcvSimple(_NUM_, _NAME_)
#endif	/* __DeclareRcvSimple */

#ifndef	__BeforeRcvSimple
#define	__BeforeRcvSimple(_NUM_, _NAME_)
#endif	/* __BeforeRcvSimple */

#ifndef	__AfterRcvSimple
#define	__AfterRcvSimple(_NUM_, _NAME_)
#endif	/* __AfterRcvSimple */

#define novalue void

#if	__MigKernelSpecificCode
#define msgh_request_port	msgh_remote_port
#define MACH_MSGH_BITS_REQUEST(bits)	MACH_MSGH_BITS_REMOTE(bits)
#define msgh_reply_port		msgh_local_port
#define MACH_MSGH_BITS_REPLY(bits)	MACH_MSGH_BITS_LOCAL(bits)
#else
#define msgh_request_port	msgh_local_port
#define MACH_MSGH_BITS_REQUEST(bits)	MACH_MSGH_BITS_LOCAL(bits)
#define msgh_reply_port		msgh_remote_port
#define MACH_MSGH_BITS_REPLY(bits)	MACH_MSGH_BITS_REMOTE(bits)
#endif /* __MigKernelSpecificCode */

#define MIG_RETURN_ERROR(X, code)	{\
				((mig_reply_error_t *)X)->RetCode = code;\
				((mig_reply_error_t *)X)->NDR = NDR_record;\
				return;\
				}

/* Forward Declarations */


mig_internal novalue _Xmach_vm_allocate_external
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_deallocate
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_protect
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_inherit
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_read
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_read_list
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_write
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_copy
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_read_overwrite
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_msync
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_behavior_set
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_map_external
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_machine_attribute
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_remap_external
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_page_query
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_region_recurse
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_region
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _X_mach_make_memory_entry
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_purgable_control_external
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_page_info
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_page_range_query
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_remap_new_external
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_deferred_reclamation_buffer_init
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_deferred_reclamation_buffer_synchronize
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_deferred_reclamation_buffer_update_reclaimable_bytes
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);

mig_internal novalue _Xmach_vm_range_create
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP);


#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_allocate_external_t__defined)
#define __MIG_check__Request__mach_vm_allocate_external_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_allocate_external_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_allocate_external_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_allocate_external_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_allocate_external_t __Request;
	typedef __RequestUData__mach_vm_allocate_external_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_allocate_external_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_allocate_external */
mig_internal novalue _Xmach_vm_allocate_external
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut address;
		mach_vm_size_ut size;
		int flags;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_allocate_external_t RequestK;
	typedef __RequestUData__mach_vm_allocate_external_t __RequestU;
	typedef __ReplyKData__mach_vm_allocate_external_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_allocate_external_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_allocate_external_t Reply __attribute__((unused));
	typedef __Request__mach_vm_allocate_external_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_allocate_external_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_allocate_external_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target;

	__DeclareRcvRpc(4800, "mach_vm_allocate_external")
	__BeforeRcvRpc(4800, "mach_vm_allocate_external")

#if	defined(__MIG_check__Request__mach_vm_allocate_external_t__defined)
	check_result = __MIG_check__Request__mach_vm_allocate_external_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_allocate_external_t__defined) */

	target = convert_port_entry_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_allocate_external(target, &In0UP->address, In0UP->size, In0UP->flags);
	vm_map_deallocate(target);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->address = In0UP->address;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4800, "mach_vm_allocate_external")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_deallocate_t__defined)
#define __MIG_check__Request__mach_vm_deallocate_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_deallocate_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_deallocate_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_deallocate_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_deallocate_t __Request;
	typedef __RequestUData__mach_vm_deallocate_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_deallocate_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_deallocate */
mig_internal novalue _Xmach_vm_deallocate
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut address;
		mach_vm_size_ut size;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_deallocate_t RequestK;
	typedef __RequestUData__mach_vm_deallocate_t __RequestU;
	typedef __ReplyKData__mach_vm_deallocate_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_deallocate_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_deallocate_t Reply __attribute__((unused));
	typedef __Request__mach_vm_deallocate_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_deallocate_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_deallocate_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target;

	__DeclareRcvRpc(4801, "mach_vm_deallocate")
	__BeforeRcvRpc(4801, "mach_vm_deallocate")

#if	defined(__MIG_check__Request__mach_vm_deallocate_t__defined)
	check_result = __MIG_check__Request__mach_vm_deallocate_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_deallocate_t__defined) */

	target = convert_port_entry_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_deallocate(target, In0UP->address, In0UP->size);
	vm_map_deallocate(target);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4801, "mach_vm_deallocate")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_protect_t__defined)
#define __MIG_check__Request__mach_vm_protect_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_protect_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_protect_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_protect_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_protect_t __Request;
	typedef __RequestUData__mach_vm_protect_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_protect_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_protect */
mig_internal novalue _Xmach_vm_protect
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		mach_vm_size_t size;
		boolean_t set_maximum;
		vm_prot_t new_protection;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_protect_t RequestK;
	typedef __RequestUData__mach_vm_protect_t __RequestU;
	typedef __ReplyKData__mach_vm_protect_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_protect_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_protect_t Reply __attribute__((unused));
	typedef __Request__mach_vm_protect_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_protect_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_protect_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4802, "mach_vm_protect")
	__BeforeRcvRpc(4802, "mach_vm_protect")

#if	defined(__MIG_check__Request__mach_vm_protect_t__defined)
	check_result = __MIG_check__Request__mach_vm_protect_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_protect_t__defined) */

	target_task = convert_port_entry_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_protect(target_task, In0UP->address, In0UP->size, In0UP->set_maximum, In0UP->new_protection);
	vm_map_deallocate(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4802, "mach_vm_protect")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_inherit_t__defined)
#define __MIG_check__Request__mach_vm_inherit_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_inherit_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_inherit_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_inherit_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_inherit_t __Request;
	typedef __RequestUData__mach_vm_inherit_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_inherit_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_inherit */
mig_internal novalue _Xmach_vm_inherit
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		mach_vm_size_t size;
		vm_inherit_t new_inheritance;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_inherit_t RequestK;
	typedef __RequestUData__mach_vm_inherit_t __RequestU;
	typedef __ReplyKData__mach_vm_inherit_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_inherit_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_inherit_t Reply __attribute__((unused));
	typedef __Request__mach_vm_inherit_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_inherit_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_inherit_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4803, "mach_vm_inherit")
	__BeforeRcvRpc(4803, "mach_vm_inherit")

#if	defined(__MIG_check__Request__mach_vm_inherit_t__defined)
	check_result = __MIG_check__Request__mach_vm_inherit_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_inherit_t__defined) */

	target_task = convert_port_entry_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_inherit(target_task, In0UP->address, In0UP->size, In0UP->new_inheritance);
	vm_map_deallocate(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4803, "mach_vm_inherit")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_read_t__defined)
#define __MIG_check__Request__mach_vm_read_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_read_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_read_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_read_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_read_t __Request;
	typedef __RequestUData__mach_vm_read_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_read_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_read */
mig_internal novalue _Xmach_vm_read
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut address;
		mach_vm_size_ut size;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_read_t RequestK;
	typedef __RequestUData__mach_vm_read_t __RequestU;
	typedef __ReplyKData__mach_vm_read_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_read_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_read_t Reply __attribute__((unused));
	typedef __Request__mach_vm_read_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_read_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_read_t__defined */

#if	__MigKernelSpecificCode
#if	UseStaticTemplates
	const static mach_msg_ool_descriptor_t dataTemplate = {
		/* addr = */		(void *)0,
		/* size = */		0,
		/* deal = */		FALSE,
		/* copy = */		MACH_MSG_VIRTUAL_COPY,
		/* pad2 = */		0,
		/* type = */		MACH_MSG_OOL_DESCRIPTOR,
	};
#endif	/* UseStaticTemplates */

#else
#if	UseStaticTemplates
	const static mach_msg_ool_descriptor_t dataTemplate = {
		/* addr = */		(void *)0,
		/* size = */		0,
		/* deal = */		FALSE,
		/* copy = */		MACH_MSG_VIRTUAL_COPY,
		/* pad2 = */		0,
		/* type = */		MACH_MSG_OOL_DESCRIPTOR,
	};
#endif	/* UseStaticTemplates */

#endif /* __MigKernelSpecificCode */
	kern_return_t RetCode;
	vm_map_read_t target_task;
	vm_offset_t data;

	__DeclareRcvRpc(4804, "mach_vm_read")
	__BeforeRcvRpc(4804, "mach_vm_read")

#if	defined(__MIG_check__Request__mach_vm_read_t__defined)
	check_result = __MIG_check__Request__mach_vm_read_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_read_t__defined) */

#if	UseStaticTemplates
	OutKP->data = dataTemplate;
#else	/* UseStaticTemplates */
	OutKP->data.deallocate =  FALSE;
	OutKP->data.copy = MACH_MSG_VIRTUAL_COPY;
	OutKP->data.pad1 = 0;
	OutKP->data.type = MACH_MSG_OOL_DESCRIPTOR;
#if defined(KERNEL) && !defined(__LP64__)
	OutKP->data.pad_end = 0;
#endif
#endif	/* UseStaticTemplates */


	target_task = convert_port_to_map_read(InKP->Head.msgh_request_port);

	RetCode = mach_vm_read(target_task, In0UP->address, In0UP->size, &data, &OutUP->dataCnt);
	vm_map_read_deallocate(target_task);
	if (RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */
	OutKP->data.address = (void *)data;
	OutKP->data.size = OutUP->dataCnt;


	OutUP->NDR = NDR_record;


	OutKP->Head.msgh_bits |= MACH_MSGH_BITS_COMPLEX;
	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	OutKP->msgh_body.msgh_descriptor_count = 1;
	__AfterRcvRpc(4804, "mach_vm_read")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_read_list_t__defined)
#define __MIG_check__Request__mach_vm_read_list_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_read_list_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_read_list_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_read_list_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_read_list_t __Request;
	typedef __RequestUData__mach_vm_read_list_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_read_list_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_read_list */
mig_internal novalue _Xmach_vm_read_list
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_read_entry_t data_list;
		natural_t count;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_read_list_t RequestK;
	typedef __RequestUData__mach_vm_read_list_t __RequestU;
	typedef __ReplyKData__mach_vm_read_list_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_read_list_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_read_list_t Reply __attribute__((unused));
	typedef __Request__mach_vm_read_list_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_read_list_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_read_list_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_read_t target_task;

	__DeclareRcvRpc(4805, "mach_vm_read_list")
	__BeforeRcvRpc(4805, "mach_vm_read_list")

#if	defined(__MIG_check__Request__mach_vm_read_list_t__defined)
	check_result = __MIG_check__Request__mach_vm_read_list_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_read_list_t__defined) */

	target_task = convert_port_to_map_read(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_read_list(target_task, In0UP->data_list, In0UP->count);
	vm_map_read_deallocate(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	{   typedef struct { char data[4096]; } *sp;
	    * (sp) OutUP->data_list = * (sp) In0UP->data_list;
	}

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4805, "mach_vm_read_list")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_write_t__defined)
#define __MIG_check__Request__mach_vm_write_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_write_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_write_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_write_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_write_t __Request;
	typedef __RequestUData__mach_vm_write_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if (!(InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->msgh_body.msgh_descriptor_count != 1) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

#if	__MigTypeCheck
	if (InKP->data.type != MACH_MSG_OOL_DESCRIPTOR)
		return MIG_TYPE_ERROR;
#endif	/* __MigTypeCheck */

#if __MigTypeCheck
	if (InKP->data.size != In0UP->dataCnt)
		return MIG_TYPE_ERROR;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_write_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_write */
mig_internal novalue _Xmach_vm_write
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut address;
		mach_msg_type_number_t dataCnt;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_write_t RequestK;
	typedef __RequestUData__mach_vm_write_t __RequestU;
	typedef __ReplyKData__mach_vm_write_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_write_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_write_t Reply __attribute__((unused));
	typedef __Request__mach_vm_write_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_write_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_write_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4806, "mach_vm_write")
	__BeforeRcvRpc(4806, "mach_vm_write")

#if	defined(__MIG_check__Request__mach_vm_write_t__defined)
	check_result = __MIG_check__Request__mach_vm_write_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_write_t__defined) */

	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_write(target_task, In0UP->address, (vm_offset_t)(InKP->data.address), InKP->data.size);
	vm_map_deallocate(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4806, "mach_vm_write")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_copy_t__defined)
#define __MIG_check__Request__mach_vm_copy_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_copy_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_copy_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_copy_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_copy_t __Request;
	typedef __RequestUData__mach_vm_copy_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_copy_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_copy */
mig_internal novalue _Xmach_vm_copy
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut source_address;
		mach_vm_size_ut size;
		mach_vm_address_ut dest_address;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_copy_t RequestK;
	typedef __RequestUData__mach_vm_copy_t __RequestU;
	typedef __ReplyKData__mach_vm_copy_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_copy_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_copy_t Reply __attribute__((unused));
	typedef __Request__mach_vm_copy_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_copy_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_copy_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4807, "mach_vm_copy")
	__BeforeRcvRpc(4807, "mach_vm_copy")

#if	defined(__MIG_check__Request__mach_vm_copy_t__defined)
	check_result = __MIG_check__Request__mach_vm_copy_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_copy_t__defined) */

	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_copy(target_task, In0UP->source_address, In0UP->size, In0UP->dest_address);
	vm_map_deallocate(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4807, "mach_vm_copy")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_read_overwrite_t__defined)
#define __MIG_check__Request__mach_vm_read_overwrite_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_read_overwrite_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_read_overwrite_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_read_overwrite_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_read_overwrite_t __Request;
	typedef __RequestUData__mach_vm_read_overwrite_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_read_overwrite_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_read_overwrite */
mig_internal novalue _Xmach_vm_read_overwrite
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut address;
		mach_vm_size_ut size;
		mach_vm_address_ut data;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_read_overwrite_t RequestK;
	typedef __RequestUData__mach_vm_read_overwrite_t __RequestU;
	typedef __ReplyKData__mach_vm_read_overwrite_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_read_overwrite_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_read_overwrite_t Reply __attribute__((unused));
	typedef __Request__mach_vm_read_overwrite_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_read_overwrite_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_read_overwrite_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_read_t target_task;

	__DeclareRcvRpc(4808, "mach_vm_read_overwrite")
	__BeforeRcvRpc(4808, "mach_vm_read_overwrite")

#if	defined(__MIG_check__Request__mach_vm_read_overwrite_t__defined)
	check_result = __MIG_check__Request__mach_vm_read_overwrite_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_read_overwrite_t__defined) */

	target_task = convert_port_to_map_read(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_read_overwrite(target_task, In0UP->address, In0UP->size, In0UP->data, &OutUP->outsize);
	vm_map_read_deallocate(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4808, "mach_vm_read_overwrite")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_msync_t__defined)
#define __MIG_check__Request__mach_vm_msync_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_msync_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_msync_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_msync_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_msync_t __Request;
	typedef __RequestUData__mach_vm_msync_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_msync_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_msync */
mig_internal novalue _Xmach_vm_msync
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		mach_vm_size_t size;
		vm_sync_t sync_flags;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_msync_t RequestK;
	typedef __RequestUData__mach_vm_msync_t __RequestU;
	typedef __ReplyKData__mach_vm_msync_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_msync_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_msync_t Reply __attribute__((unused));
	typedef __Request__mach_vm_msync_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_msync_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_msync_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4809, "mach_vm_msync")
	__BeforeRcvRpc(4809, "mach_vm_msync")

#if	defined(__MIG_check__Request__mach_vm_msync_t__defined)
	check_result = __MIG_check__Request__mach_vm_msync_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_msync_t__defined) */

	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_msync(target_task, In0UP->address, In0UP->size, In0UP->sync_flags);
	vm_map_deallocate(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4809, "mach_vm_msync")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_behavior_set_t__defined)
#define __MIG_check__Request__mach_vm_behavior_set_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_behavior_set_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_behavior_set_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_behavior_set_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_behavior_set_t __Request;
	typedef __RequestUData__mach_vm_behavior_set_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_behavior_set_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_behavior_set */
mig_internal novalue _Xmach_vm_behavior_set
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		mach_vm_size_t size;
		vm_behavior_t new_behavior;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_behavior_set_t RequestK;
	typedef __RequestUData__mach_vm_behavior_set_t __RequestU;
	typedef __ReplyKData__mach_vm_behavior_set_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_behavior_set_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_behavior_set_t Reply __attribute__((unused));
	typedef __Request__mach_vm_behavior_set_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_behavior_set_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_behavior_set_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4810, "mach_vm_behavior_set")
	__BeforeRcvRpc(4810, "mach_vm_behavior_set")

#if	defined(__MIG_check__Request__mach_vm_behavior_set_t__defined)
	check_result = __MIG_check__Request__mach_vm_behavior_set_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_behavior_set_t__defined) */

	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_behavior_set(target_task, In0UP->address, In0UP->size, In0UP->new_behavior);
	vm_map_deallocate(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4810, "mach_vm_behavior_set")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_map_external_t__defined)
#define __MIG_check__Request__mach_vm_map_external_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_map_external_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_map_external_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_map_external_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_map_external_t __Request;
	typedef __RequestUData__mach_vm_map_external_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if (!(InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->msgh_body.msgh_descriptor_count != 1) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

#if	__MigTypeCheck
	if (InKP->object.type != MACH_MSG_PORT_DESCRIPTOR ||
	    InKP->object.disposition != 17)
		return MIG_TYPE_ERROR;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_map_external_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_map_external */
mig_internal novalue _Xmach_vm_map_external
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut address;
		mach_vm_size_ut size;
		mach_vm_offset_ut mask;
		int flags;
		memory_object_offset_ut offset;
		boolean_t copy;
		vm_prot_ut cur_protection;
		vm_prot_ut max_protection;
		vm_inherit_ut inheritance;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_map_external_t RequestK;
	typedef __RequestUData__mach_vm_map_external_t __RequestU;
	typedef __ReplyKData__mach_vm_map_external_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_map_external_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_map_external_t Reply __attribute__((unused));
	typedef __Request__mach_vm_map_external_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_map_external_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_map_external_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4811, "mach_vm_map_external")
	__BeforeRcvRpc(4811, "mach_vm_map_external")

#if	defined(__MIG_check__Request__mach_vm_map_external_t__defined)
	check_result = __MIG_check__Request__mach_vm_map_external_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_map_external_t__defined) */

	target_task = convert_port_entry_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_map_external(target_task, &In0UP->address, In0UP->size, In0UP->mask, In0UP->flags, null_conversion(InKP->object.name), In0UP->offset, In0UP->copy, In0UP->cur_protection, In0UP->max_protection, In0UP->inheritance);
	vm_map_deallocate(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
	ipc_port_release_send((ipc_port_t)InKP->object.name);
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->address = In0UP->address;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4811, "mach_vm_map_external")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_machine_attribute_t__defined)
#define __MIG_check__Request__mach_vm_machine_attribute_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_machine_attribute_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_machine_attribute_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_machine_attribute_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_machine_attribute_t __Request;
	typedef __RequestUData__mach_vm_machine_attribute_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_machine_attribute_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_machine_attribute */
mig_internal novalue _Xmach_vm_machine_attribute
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		mach_vm_size_t size;
		vm_machine_attribute_t attribute;
		vm_machine_attribute_val_t value;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_machine_attribute_t RequestK;
	typedef __RequestUData__mach_vm_machine_attribute_t __RequestU;
	typedef __ReplyKData__mach_vm_machine_attribute_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_machine_attribute_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_machine_attribute_t Reply __attribute__((unused));
	typedef __Request__mach_vm_machine_attribute_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_machine_attribute_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_machine_attribute_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4812, "mach_vm_machine_attribute")
	__BeforeRcvRpc(4812, "mach_vm_machine_attribute")

#if	defined(__MIG_check__Request__mach_vm_machine_attribute_t__defined)
	check_result = __MIG_check__Request__mach_vm_machine_attribute_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_machine_attribute_t__defined) */

	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_machine_attribute(target_task, In0UP->address, In0UP->size, In0UP->attribute, &In0UP->value);
	vm_map_deallocate(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->value = In0UP->value;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4812, "mach_vm_machine_attribute")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_remap_external_t__defined)
#define __MIG_check__Request__mach_vm_remap_external_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_remap_external_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_remap_external_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_remap_external_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_remap_external_t __Request;
	typedef __RequestUData__mach_vm_remap_external_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if (!(InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->msgh_body.msgh_descriptor_count != 1) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

#if	__MigTypeCheck
	if (InKP->src_task.type != MACH_MSG_PORT_DESCRIPTOR ||
	    InKP->src_task.disposition != 17)
		return MIG_TYPE_ERROR;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_remap_external_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_remap_external */
mig_internal novalue _Xmach_vm_remap_external
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut target_address;
		mach_vm_size_ut size;
		mach_vm_offset_ut mask;
		int flags;
		mach_vm_address_ut src_address;
		boolean_t copy;
		vm_inherit_ut inheritance;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_remap_external_t RequestK;
	typedef __RequestUData__mach_vm_remap_external_t __RequestU;
	typedef __ReplyKData__mach_vm_remap_external_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_remap_external_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_remap_external_t Reply __attribute__((unused));
	typedef __Request__mach_vm_remap_external_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_remap_external_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_remap_external_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;
	vm_map_t src_task;

	__DeclareRcvRpc(4813, "mach_vm_remap_external")
	__BeforeRcvRpc(4813, "mach_vm_remap_external")

#if	defined(__MIG_check__Request__mach_vm_remap_external_t__defined)
	check_result = __MIG_check__Request__mach_vm_remap_external_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_remap_external_t__defined) */

	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	src_task = convert_port_to_map(InKP->src_task.name);

	OutUP->RetCode = mach_vm_remap_external(target_task, &In0UP->target_address, In0UP->size, In0UP->mask, In0UP->flags, src_task, In0UP->src_address, In0UP->copy, &OutUP->cur_protection, &OutUP->max_protection, In0UP->inheritance);
	vm_map_deallocate(src_task);
	vm_map_deallocate(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
	ipc_port_release_send((ipc_port_t)InKP->src_task.name);
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->target_address = In0UP->target_address;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4813, "mach_vm_remap_external")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_page_query_t__defined)
#define __MIG_check__Request__mach_vm_page_query_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_page_query_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_page_query_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_page_query_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_page_query_t __Request;
	typedef __RequestUData__mach_vm_page_query_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_page_query_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_page_query */
mig_internal novalue _Xmach_vm_page_query
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_offset_t offset;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_page_query_t RequestK;
	typedef __RequestUData__mach_vm_page_query_t __RequestU;
	typedef __ReplyKData__mach_vm_page_query_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_page_query_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_page_query_t Reply __attribute__((unused));
	typedef __Request__mach_vm_page_query_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_page_query_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_page_query_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_read_t target_map;

	__DeclareRcvRpc(4814, "mach_vm_page_query")
	__BeforeRcvRpc(4814, "mach_vm_page_query")

#if	defined(__MIG_check__Request__mach_vm_page_query_t__defined)
	check_result = __MIG_check__Request__mach_vm_page_query_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_page_query_t__defined) */

	target_map = convert_port_to_map_read(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_page_query(target_map, In0UP->offset, &OutUP->disposition, &OutUP->ref_count);
	vm_map_read_deallocate(target_map);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4814, "mach_vm_page_query")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_region_recurse_t__defined)
#define __MIG_check__Request__mach_vm_region_recurse_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_region_recurse_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_region_recurse_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_region_recurse_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_region_recurse_t __Request;
	typedef __RequestUData__mach_vm_region_recurse_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_region_recurse_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_region_recurse */
mig_internal novalue _Xmach_vm_region_recurse
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		natural_t nesting_depth;
		mach_msg_type_number_t infoCnt;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_region_recurse_t RequestK;
	typedef __RequestUData__mach_vm_region_recurse_t __RequestU;
	typedef __ReplyKData__mach_vm_region_recurse_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_region_recurse_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_region_recurse_t Reply __attribute__((unused));
	typedef __Request__mach_vm_region_recurse_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_region_recurse_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_region_recurse_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_read_t target_task;

	__DeclareRcvRpc(4815, "mach_vm_region_recurse")
	__BeforeRcvRpc(4815, "mach_vm_region_recurse")

#if	defined(__MIG_check__Request__mach_vm_region_recurse_t__defined)
	check_result = __MIG_check__Request__mach_vm_region_recurse_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_region_recurse_t__defined) */

	target_task = convert_port_to_map_read(InKP->Head.msgh_request_port);

	OutUP->infoCnt = 19;
	if (In0UP->infoCnt < OutUP->infoCnt)
		OutUP->infoCnt = In0UP->infoCnt;

	OutUP->RetCode = mach_vm_region_recurse(target_task, &In0UP->address, &OutUP->size, &In0UP->nesting_depth, OutUP->info, &OutUP->infoCnt);
	vm_map_read_deallocate(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->address = In0UP->address;

	OutUP->nesting_depth = In0UP->nesting_depth;
	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply) - 76) + (((4 * OutUP->infoCnt)));

	__AfterRcvRpc(4815, "mach_vm_region_recurse")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_region_t__defined)
#define __MIG_check__Request__mach_vm_region_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_region_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_region_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_region_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_region_t __Request;
	typedef __RequestUData__mach_vm_region_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_region_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_region */
mig_internal novalue _Xmach_vm_region
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		vm_region_flavor_t flavor;
		mach_msg_type_number_t infoCnt;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_region_t RequestK;
	typedef __RequestUData__mach_vm_region_t __RequestU;
	typedef __ReplyKData__mach_vm_region_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_region_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_region_t Reply __attribute__((unused));
	typedef __Request__mach_vm_region_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_region_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_region_t__defined */

#if	__MigKernelSpecificCode
#if	UseStaticTemplates
	const static mach_msg_port_descriptor_t object_nameTemplate = {
		/* name = */		MACH_PORT_NULL,
		/* pad1 = */		0,
		/* pad2 = */		0,
		/* disp = */		17,
		/* type = */		MACH_MSG_PORT_DESCRIPTOR,
	};
#endif	/* UseStaticTemplates */

#else
#if	UseStaticTemplates
	const static mach_msg_port_descriptor_t object_nameTemplate = {
		/* name = */		MACH_PORT_NULL,
		/* pad1 = */		0,
		/* pad2 = */		0,
		/* disp = */		17,
		/* type = */		MACH_MSG_PORT_DESCRIPTOR,
	};
#endif	/* UseStaticTemplates */

#endif /* __MigKernelSpecificCode */
	kern_return_t RetCode;
	vm_map_read_t target_task;
	mach_port_t object_name;

	__DeclareRcvRpc(4816, "mach_vm_region")
	__BeforeRcvRpc(4816, "mach_vm_region")

#if	defined(__MIG_check__Request__mach_vm_region_t__defined)
	check_result = __MIG_check__Request__mach_vm_region_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_region_t__defined) */

#if	UseStaticTemplates
	OutKP->object_name = object_nameTemplate;
#else	/* UseStaticTemplates */
#if __MigKernelSpecificCode
	OutKP->object_name.disposition = 17;
#else
	OutKP->object_name.disposition = 17;
#endif /* __MigKernelSpecificCode */
#if !(defined(KERNEL) && defined(__LP64__))
	OutKP->object_name.pad1 = 0;
#endif
	OutKP->object_name.pad2 = 0;
	OutKP->object_name.type = MACH_MSG_PORT_DESCRIPTOR;
#if defined(KERNEL)
	OutKP->object_name.pad_end = 0;
#endif
#endif	/* UseStaticTemplates */


	target_task = convert_port_to_map_read(InKP->Head.msgh_request_port);

	OutUP->infoCnt = 10;
	if (In0UP->infoCnt < OutUP->infoCnt)
		OutUP->infoCnt = In0UP->infoCnt;

	RetCode = mach_vm_region(target_task, &In0UP->address, &OutUP->size, In0UP->flavor, OutUP->info, &OutUP->infoCnt, &object_name);
	vm_map_read_deallocate(target_task);
	if (RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */
	OutKP->object_name.name = object_name;


	OutUP->NDR = NDR_record;


	OutUP->address = In0UP->address;
	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply) - 40) + (((4 * OutUP->infoCnt)));

	OutKP->Head.msgh_bits |= MACH_MSGH_BITS_COMPLEX;
	OutKP->msgh_body.msgh_descriptor_count = 1;
	__AfterRcvRpc(4816, "mach_vm_region")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request___mach_make_memory_entry_t__defined)
#define __MIG_check__Request___mach_make_memory_entry_t__defined

mig_internal kern_return_t __MIG_check__Request___mach_make_memory_entry_t(
	__attribute__((__unused__)) __RequestKData___mach_make_memory_entry_t *InKP,
	__attribute__((__unused__)) __RequestUData___mach_make_memory_entry_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request___mach_make_memory_entry_t __Request;
	typedef __RequestUData___mach_make_memory_entry_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if (!(InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->msgh_body.msgh_descriptor_count != 1) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

#if	__MigTypeCheck
	if (InKP->parent_handle.type != MACH_MSG_PORT_DESCRIPTOR ||
	    InKP->parent_handle.disposition != 17)
		return MIG_TYPE_ERROR;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request___mach_make_memory_entry_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine _mach_make_memory_entry */
mig_internal novalue _X_mach_make_memory_entry
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		memory_object_size_ut size;
		memory_object_offset_ut offset;
		vm_prot_ut permission;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData___mach_make_memory_entry_t RequestK;
	typedef __RequestUData___mach_make_memory_entry_t __RequestU;
	typedef __ReplyKData___mach_make_memory_entry_t ReplyK __attribute__((unused));
	typedef __ReplyUData___mach_make_memory_entry_t ReplyU __attribute__((unused));
	typedef __Reply___mach_make_memory_entry_t Reply __attribute__((unused));
	typedef __Request___mach_make_memory_entry_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request___mach_make_memory_entry_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request___mach_make_memory_entry_t__defined */

#if	__MigKernelSpecificCode
#if	UseStaticTemplates
	const static mach_msg_port_descriptor_t object_handleTemplate = {
		/* name = */		MACH_PORT_NULL,
		/* pad1 = */		0,
		/* pad2 = */		0,
		/* disp = */		17,
		/* type = */		MACH_MSG_PORT_DESCRIPTOR,
	};
#endif	/* UseStaticTemplates */

#else
#if	UseStaticTemplates
	const static mach_msg_port_descriptor_t object_handleTemplate = {
		/* name = */		MACH_PORT_NULL,
		/* pad1 = */		0,
		/* pad2 = */		0,
		/* disp = */		17,
		/* type = */		MACH_MSG_PORT_DESCRIPTOR,
	};
#endif	/* UseStaticTemplates */

#endif /* __MigKernelSpecificCode */
	kern_return_t RetCode;
	vm_map_t target_task;
	mem_entry_name_port_t object_handle;

	__DeclareRcvRpc(4817, "_mach_make_memory_entry")
	__BeforeRcvRpc(4817, "_mach_make_memory_entry")

#if	defined(__MIG_check__Request___mach_make_memory_entry_t__defined)
	check_result = __MIG_check__Request___mach_make_memory_entry_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request___mach_make_memory_entry_t__defined) */

#if	UseStaticTemplates
	OutKP->object_handle = object_handleTemplate;
#else	/* UseStaticTemplates */
#if __MigKernelSpecificCode
	OutKP->object_handle.disposition = 17;
#else
	OutKP->object_handle.disposition = 17;
#endif /* __MigKernelSpecificCode */
#if !(defined(KERNEL) && defined(__LP64__))
	OutKP->object_handle.pad1 = 0;
#endif
	OutKP->object_handle.pad2 = 0;
	OutKP->object_handle.type = MACH_MSG_PORT_DESCRIPTOR;
#if defined(KERNEL)
	OutKP->object_handle.pad_end = 0;
#endif
#endif	/* UseStaticTemplates */


	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	RetCode = _mach_make_memory_entry(target_task, &In0UP->size, In0UP->offset, In0UP->permission, &object_handle, null_conversion(InKP->parent_handle.name));
	vm_map_deallocate(target_task);
	if (RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, RetCode);
	}
#if	__MigKernelSpecificCode
	ipc_port_release_send((ipc_port_t)InKP->parent_handle.name);
#endif /* __MigKernelSpecificCode */
	OutKP->object_handle.name = (mach_port_t)null_conversion(object_handle);


	OutUP->NDR = NDR_record;


	OutUP->size = In0UP->size;

	OutKP->Head.msgh_bits |= MACH_MSGH_BITS_COMPLEX;
	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	OutKP->msgh_body.msgh_descriptor_count = 1;
	__AfterRcvRpc(4817, "_mach_make_memory_entry")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_purgable_control_external_t__defined)
#define __MIG_check__Request__mach_vm_purgable_control_external_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_purgable_control_external_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_purgable_control_external_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_purgable_control_external_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_purgable_control_external_t __Request;
	typedef __RequestUData__mach_vm_purgable_control_external_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_purgable_control_external_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_purgable_control_external */
mig_internal novalue _Xmach_vm_purgable_control_external
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		vm_purgable_t control;
		int state;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_purgable_control_external_t RequestK;
	typedef __RequestUData__mach_vm_purgable_control_external_t __RequestU;
	typedef __ReplyKData__mach_vm_purgable_control_external_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_purgable_control_external_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_purgable_control_external_t Reply __attribute__((unused));
	typedef __Request__mach_vm_purgable_control_external_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_purgable_control_external_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_purgable_control_external_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	__DeclareRcvRpc(4818, "mach_vm_purgable_control_external")
	__BeforeRcvRpc(4818, "mach_vm_purgable_control_external")

#if	defined(__MIG_check__Request__mach_vm_purgable_control_external_t__defined)
	check_result = __MIG_check__Request__mach_vm_purgable_control_external_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_purgable_control_external_t__defined) */

	OutUP->RetCode = mach_vm_purgable_control_external(InKP->Head.msgh_request_port, In0UP->address, In0UP->control, &In0UP->state);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->state = In0UP->state;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4818, "mach_vm_purgable_control_external")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_page_info_t__defined)
#define __MIG_check__Request__mach_vm_page_info_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_page_info_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_page_info_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_page_info_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_page_info_t __Request;
	typedef __RequestUData__mach_vm_page_info_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_page_info_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_page_info */
mig_internal novalue _Xmach_vm_page_info
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		vm_page_info_flavor_t flavor;
		mach_msg_type_number_t infoCnt;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_page_info_t RequestK;
	typedef __RequestUData__mach_vm_page_info_t __RequestU;
	typedef __ReplyKData__mach_vm_page_info_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_page_info_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_page_info_t Reply __attribute__((unused));
	typedef __Request__mach_vm_page_info_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_page_info_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_page_info_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_read_t target_task;

	__DeclareRcvRpc(4819, "mach_vm_page_info")
	__BeforeRcvRpc(4819, "mach_vm_page_info")

#if	defined(__MIG_check__Request__mach_vm_page_info_t__defined)
	check_result = __MIG_check__Request__mach_vm_page_info_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_page_info_t__defined) */

	target_task = convert_port_to_map_read(InKP->Head.msgh_request_port);

	OutUP->infoCnt = 32;
	if (In0UP->infoCnt < OutUP->infoCnt)
		OutUP->infoCnt = In0UP->infoCnt;

	OutUP->RetCode = mach_vm_page_info(target_task, In0UP->address, In0UP->flavor, OutUP->info, &OutUP->infoCnt);
	vm_map_read_deallocate(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply) - 128) + (((4 * OutUP->infoCnt)));

	__AfterRcvRpc(4819, "mach_vm_page_info")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_page_range_query_t__defined)
#define __MIG_check__Request__mach_vm_page_range_query_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_page_range_query_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_page_range_query_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_page_range_query_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_page_range_query_t __Request;
	typedef __RequestUData__mach_vm_page_range_query_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_page_range_query_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_page_range_query */
mig_internal novalue _Xmach_vm_page_range_query
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_offset_t address;
		mach_vm_size_t size;
		mach_vm_address_t dispositions;
		mach_vm_size_t dispositions_count;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_page_range_query_t RequestK;
	typedef __RequestUData__mach_vm_page_range_query_t __RequestU;
	typedef __ReplyKData__mach_vm_page_range_query_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_page_range_query_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_page_range_query_t Reply __attribute__((unused));
	typedef __Request__mach_vm_page_range_query_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_page_range_query_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_page_range_query_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_read_t target_map;

	__DeclareRcvRpc(4820, "mach_vm_page_range_query")
	__BeforeRcvRpc(4820, "mach_vm_page_range_query")

#if	defined(__MIG_check__Request__mach_vm_page_range_query_t__defined)
	check_result = __MIG_check__Request__mach_vm_page_range_query_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_page_range_query_t__defined) */

	target_map = convert_port_to_map_read(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_page_range_query(target_map, In0UP->address, In0UP->size, In0UP->dispositions, &In0UP->dispositions_count);
	vm_map_read_deallocate(target_map);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->dispositions_count = In0UP->dispositions_count;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4820, "mach_vm_page_range_query")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_remap_new_external_t__defined)
#define __MIG_check__Request__mach_vm_remap_new_external_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_remap_new_external_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_remap_new_external_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_remap_new_external_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_remap_new_external_t __Request;
	typedef __RequestUData__mach_vm_remap_new_external_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if (!(InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->msgh_body.msgh_descriptor_count != 1) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

#if	__MigTypeCheck
	if (InKP->src_tport.type != MACH_MSG_PORT_DESCRIPTOR ||
	    InKP->src_tport.disposition != 17)
		return MIG_TYPE_ERROR;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_remap_new_external_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_remap_new_external */
mig_internal novalue _Xmach_vm_remap_new_external
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_ut target_address;
		mach_vm_size_ut size;
		mach_vm_offset_ut mask;
		int flags;
		mach_vm_address_ut src_address;
		boolean_t copy;
		vm_prot_ut cur_protection;
		vm_prot_ut max_protection;
		vm_inherit_ut inheritance;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_remap_new_external_t RequestK;
	typedef __RequestUData__mach_vm_remap_new_external_t __RequestU;
	typedef __ReplyKData__mach_vm_remap_new_external_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_remap_new_external_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_remap_new_external_t Reply __attribute__((unused));
	typedef __Request__mach_vm_remap_new_external_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_remap_new_external_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_remap_new_external_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4821, "mach_vm_remap_new_external")
	__BeforeRcvRpc(4821, "mach_vm_remap_new_external")

#if	defined(__MIG_check__Request__mach_vm_remap_new_external_t__defined)
	check_result = __MIG_check__Request__mach_vm_remap_new_external_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_remap_new_external_t__defined) */

	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_remap_new_external(target_task, &In0UP->target_address, In0UP->size, In0UP->mask, In0UP->flags, InKP->src_tport.name, In0UP->src_address, In0UP->copy, &In0UP->cur_protection, &In0UP->max_protection, In0UP->inheritance);
	vm_map_deallocate(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->target_address = In0UP->target_address;

	OutUP->cur_protection = In0UP->cur_protection;

	OutUP->max_protection = In0UP->max_protection;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4821, "mach_vm_remap_new_external")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t__defined)
#define __MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_deferred_reclamation_buffer_init_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_deferred_reclamation_buffer_init_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_deferred_reclamation_buffer_init_t __Request;
	typedef __RequestUData__mach_vm_deferred_reclamation_buffer_init_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_deferred_reclamation_buffer_init */
mig_internal novalue _Xmach_vm_deferred_reclamation_buffer_init
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_address_t address;
		mach_vm_size_t size;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_deferred_reclamation_buffer_init_t RequestK;
	typedef __RequestUData__mach_vm_deferred_reclamation_buffer_init_t __RequestU;
	typedef __ReplyKData__mach_vm_deferred_reclamation_buffer_init_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_deferred_reclamation_buffer_init_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_deferred_reclamation_buffer_init_t Reply __attribute__((unused));
	typedef __Request__mach_vm_deferred_reclamation_buffer_init_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	task_t target_task;

	__DeclareRcvRpc(4822, "mach_vm_deferred_reclamation_buffer_init")
	__BeforeRcvRpc(4822, "mach_vm_deferred_reclamation_buffer_init")

#if	defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t__defined)
	check_result = __MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_init_t__defined) */

	target_task = convert_port_to_task_mig(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_deferred_reclamation_buffer_init(target_task, &In0UP->address, In0UP->size);
	task_deallocate_mig(target_task);
	if (OutUP->RetCode != KERN_SUCCESS) {
		MIG_RETURN_ERROR(OutKP, OutUP->RetCode);
	}
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	OutUP->address = In0UP->address;

	OutKP->Head.msgh_size = (mach_msg_size_t)(sizeof(Reply));
	__AfterRcvRpc(4822, "mach_vm_deferred_reclamation_buffer_init")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t__defined)
#define __MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_deferred_reclamation_buffer_synchronize_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_deferred_reclamation_buffer_synchronize_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_deferred_reclamation_buffer_synchronize_t __Request;
	typedef __RequestUData__mach_vm_deferred_reclamation_buffer_synchronize_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_deferred_reclamation_buffer_synchronize */
mig_internal novalue _Xmach_vm_deferred_reclamation_buffer_synchronize
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_size_t num_entries_to_reclaim;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_deferred_reclamation_buffer_synchronize_t RequestK;
	typedef __RequestUData__mach_vm_deferred_reclamation_buffer_synchronize_t __RequestU;
	typedef __ReplyKData__mach_vm_deferred_reclamation_buffer_synchronize_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_deferred_reclamation_buffer_synchronize_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_deferred_reclamation_buffer_synchronize_t Reply __attribute__((unused));
	typedef __Request__mach_vm_deferred_reclamation_buffer_synchronize_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	task_t target_task;

	__DeclareRcvRpc(4823, "mach_vm_deferred_reclamation_buffer_synchronize")
	__BeforeRcvRpc(4823, "mach_vm_deferred_reclamation_buffer_synchronize")

#if	defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t__defined)
	check_result = __MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_synchronize_t__defined) */

	target_task = convert_port_to_task_mig(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_deferred_reclamation_buffer_synchronize(target_task, In0UP->num_entries_to_reclaim);
	task_deallocate_mig(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4823, "mach_vm_deferred_reclamation_buffer_synchronize")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t__defined)
#define __MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t __Request;
	typedef __RequestUData__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (InKP->Head.msgh_size != (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes */
mig_internal novalue _Xmach_vm_deferred_reclamation_buffer_update_reclaimable_bytes
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_size_t reclaimable_bytes;
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t RequestK;
	typedef __RequestUData__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t __RequestU;
	typedef __ReplyKData__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t Reply __attribute__((unused));
	typedef __Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	task_t target_task;

	__DeclareRcvRpc(4824, "mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes")
	__BeforeRcvRpc(4824, "mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes")

#if	defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t__defined)
	check_result = __MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t__defined) */

	target_task = convert_port_to_task_mig(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes(target_task, In0UP->reclaimable_bytes);
	task_deallocate_mig(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4824, "mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes")
}

#if ( __MigTypeCheck )
#if __MIG_check__Request__mach_vm_subsystem__
#if !defined(__MIG_check__Request__mach_vm_range_create_t__defined)
#define __MIG_check__Request__mach_vm_range_create_t__defined

mig_internal kern_return_t __MIG_check__Request__mach_vm_range_create_t(
	__attribute__((__unused__)) __RequestKData__mach_vm_range_create_t *InKP,
	__attribute__((__unused__)) __RequestUData__mach_vm_range_create_t *In0UP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP)
{

	typedef __Request__mach_vm_range_create_t __Request;
	typedef __RequestUData__mach_vm_range_create_t __RequestU __attribute__((unused));
#if	__MigTypeCheck
	unsigned int msgh_size;
#endif	/* __MigTypeCheck */

#if	__MigTypeCheck
	msgh_size = InKP->Head.msgh_size;
	if ((InKP->Head.msgh_bits & MACH_MSGH_BITS_COMPLEX) ||
	    (msgh_size < (mach_msg_size_t)(sizeof(__Request) - 1024)) ||  (msgh_size > (mach_msg_size_t)sizeof(__Request)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

#if defined(__NDR_convert__int_rep__Request__mach_vm_range_create_t__recipesCnt__defined)
	if (In0UP->NDR.int_rep != NDR_record.int_rep)
		__NDR_convert__int_rep__Request__mach_vm_range_create_t__recipesCnt(&In0UP->recipesCnt, In0UP->NDR.int_rep);
#endif	/* __NDR_convert__int_rep__Request__mach_vm_range_create_t__recipesCnt__defined */
#if	__MigTypeCheck
	if (In0UP->recipesCnt > 1024)
		return MIG_BAD_ARGUMENTS;
	if (((msgh_size - (mach_msg_size_t)(sizeof(__Request) - 1024)) < In0UP->recipesCnt) ||
	    (msgh_size != (mach_msg_size_t)(sizeof(__Request) - 1024) + _WALIGN_(In0UP->recipesCnt)))
		return MIG_BAD_ARGUMENTS;
#endif	/* __MigTypeCheck */

	return MACH_MSG_SUCCESS;
}
#endif /* !defined(__MIG_check__Request__mach_vm_range_create_t__defined) */
#endif /* __MIG_check__Request__mach_vm_subsystem__ */
#endif /* ( __MigTypeCheck ) */


/* Routine mach_vm_range_create */
mig_internal novalue _Xmach_vm_range_create
	(mach_msg_header_t *InHeadP, __attribute__((__unused__)) void *InDataP,
	__attribute__((__unused__)) mach_msg_max_trailer_t *InTrailerP,
	mach_msg_header_t *OutHeadP, __attribute__((__unused__)) void *OutDataP)
{

#ifdef  __MigPackStructs
#pragma pack(push, 4)
#endif
	typedef struct {
		NDR_record_t NDR;
		mach_vm_range_flavor_t flavor;
		mach_msg_type_number_t recipesCnt;
		uint8_t recipes[1024];
		mach_msg_trailer_t trailer;
		char padding[0]; /* Avoid generating empty UData structs */
	} RequestU __attribute__((unused));
#ifdef  __MigPackStructs
#pragma pack(pop)
#endif
	typedef __RequestKData__mach_vm_range_create_t RequestK;
	typedef __RequestUData__mach_vm_range_create_t __RequestU;
	typedef __ReplyKData__mach_vm_range_create_t ReplyK __attribute__((unused));
	typedef __ReplyUData__mach_vm_range_create_t ReplyU __attribute__((unused));
	typedef __Reply__mach_vm_range_create_t Reply __attribute__((unused));
	typedef __Request__mach_vm_range_create_t __Request __attribute__((unused));

	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	RequestK *InKP = (RequestK *) InHeadP;
	RequestU *In0UP = (RequestU *) InDataP;
	ReplyK *OutKP = (ReplyK *) OutHeadP;
	ReplyU *OutUP = (ReplyU *) OutDataP;
	(void)OutUP;
#ifdef	__MIG_check__Request__mach_vm_range_create_t__defined
	kern_return_t check_result;
#endif	/* __MIG_check__Request__mach_vm_range_create_t__defined */

#if	__MigKernelSpecificCode
#else
#endif /* __MigKernelSpecificCode */
	vm_map_t target_task;

	__DeclareRcvRpc(4825, "mach_vm_range_create")
	__BeforeRcvRpc(4825, "mach_vm_range_create")

#if	defined(__MIG_check__Request__mach_vm_range_create_t__defined)
	check_result = __MIG_check__Request__mach_vm_range_create_t((RequestK *)InKP, (__RequestU *)In0UP, InTrailerP);
	if (check_result != MACH_MSG_SUCCESS)
		{ MIG_RETURN_ERROR(OutKP, check_result); }
#endif	/* defined(__MIG_check__Request__mach_vm_range_create_t__defined) */

	target_task = convert_port_to_map(InKP->Head.msgh_request_port);

	OutUP->RetCode = mach_vm_range_create(target_task, In0UP->flavor, In0UP->recipes, In0UP->recipesCnt);
	vm_map_deallocate(target_task);
#if	__MigKernelSpecificCode
#endif /* __MigKernelSpecificCode */

	OutUP->NDR = NDR_record;


	__AfterRcvRpc(4825, "mach_vm_range_create")
}



/* Description of this kernel subsystem, for use in direct RPC */
const struct mach_vm_subsystem mach_vm_subsystem = {
	mach_vm_server_routine,
	4800,
	4826,
	(mach_msg_size_t)sizeof(union __ReplyUnion__mach_vm_subsystem),
	(vm_address_t)0,
	{
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_allocate_external, 5, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_allocate_external_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_deallocate, 5, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_deallocate_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_protect, 7, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_protect_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_inherit, 6, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_inherit_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_read, 7, 0, 1, (mach_msg_size_t)sizeof(__Reply__mach_vm_read_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_read_list, 3, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_read_list_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_write, 5, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_write_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_copy, 7, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_copy_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_read_overwrite, 8, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_read_overwrite_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_msync, 6, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_msync_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_behavior_set, 6, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_behavior_set_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_map_external, 14, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_map_external_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_machine_attribute, 7, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_machine_attribute_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_remap_external, 14, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_remap_external_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_page_query, 5, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_page_query_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_region_recurse, 6, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_region_recurse_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_region, 7, 0, 1, (mach_msg_size_t)sizeof(__Reply__mach_vm_region_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _X_mach_make_memory_entry, 7, 0, 1, (mach_msg_size_t)sizeof(__Reply___mach_make_memory_entry_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_purgable_control_external, 5, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_purgable_control_external_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_page_info, 6, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_page_info_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_page_range_query, 8, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_page_range_query_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_remap_new_external, 14, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_remap_new_external_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_deferred_reclamation_buffer_init, 4, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_deferred_reclamation_buffer_init_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_deferred_reclamation_buffer_synchronize, 3, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_deferred_reclamation_buffer_synchronize_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_deferred_reclamation_buffer_update_reclaimable_bytes, 3, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_deferred_reclamation_buffer_update_reclaimable_bytes_t)},
          { (mig_impl_routine_t) 0,
          (mig_stub_kern_routine_t) _Xmach_vm_range_create, 4, 0, 0, (mach_msg_size_t)sizeof(__Reply__mach_vm_range_create_t)},
	}
};

mig_external boolean_t mach_vm_server
	(mach_msg_header_t *InHeadP, void *InDataP, mach_msg_max_trailer_t *InTrailerP, mach_msg_header_t *OutHeadP, void *OutDataP)
{
	/*
	 * typedef struct {
	 * 	mach_msg_header_t Head;
	 * 	NDR_record_t NDR;
	 * 	kern_return_t RetCode;
	 * } mig_reply_error_t;
	 */

	mig_kern_routine_t routine;

	OutHeadP->msgh_bits = MACH_MSGH_BITS(MACH_MSGH_BITS_REPLY(InHeadP->msgh_bits), 0);
	OutHeadP->msgh_remote_port = InHeadP->msgh_reply_port;
	/* Minimal size: routine() will update it if different */
	OutHeadP->msgh_size = (mach_msg_size_t)sizeof(mig_reply_error_t);
	OutHeadP->msgh_local_port = MACH_PORT_NULL;
	OutHeadP->msgh_id = InHeadP->msgh_id + 100;
	OutHeadP->msgh_reserved = 0;

	if ((InHeadP->msgh_id > 4825) || (InHeadP->msgh_id < 4800) ||
	    ((routine = mach_vm_subsystem.kroutine[InHeadP->msgh_id - 4800].kstub_routine) == 0)) {
		((mig_reply_error_t *)OutHeadP)->NDR = NDR_record;
		((mig_reply_error_t *)OutHeadP)->RetCode = MIG_BAD_ID;
		return FALSE;
	}
	(*routine) (InHeadP, InDataP, InTrailerP, OutHeadP, OutDataP);
	return TRUE;
}

mig_external mig_kern_routine_t mach_vm_server_routine
	(mach_msg_header_t *InHeadP)
{
	int msgh_id;

	msgh_id = InHeadP->msgh_id - 4800;

	if ((msgh_id > 25) || (msgh_id < 0))
		return 0;

	return mach_vm_subsystem.kroutine[msgh_id].kstub_routine;
}
